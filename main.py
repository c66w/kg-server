from fastapi import FastAPI, UploadFile, File, HTTPException, Depends
from fastapi.responses import JSONResponse, RedirectResponse
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from fastapi.security import HTTPBearer
import pandas as pd
import io
import os
import json
import re
from typing import List, Dict, Any
from datetime import datetime

app = FastAPI(title="CSVä¸‰å…ƒç»„è§£ææœåŠ¡", description="æ”¯æŒå¤šçŸ¥è¯†åº“çš„CSVåˆ°ä¸‰å…ƒç»„è½¬æ¢")

# å®‰å…¨é…ç½®
security = HTTPBearer(auto_error=False)

# æ–‡ä»¶å¤§å°é™åˆ¶ (50MB)
MAX_FILE_SIZE = 50 * 1024 * 1024

# å…è®¸çš„æ–‡ä»¶ç±»å‹
ALLOWED_EXTENSIONS = {'.csv'}

def validate_space_name(space_name: str) -> bool:
    """éªŒè¯çŸ¥è¯†åº“åç§°æ˜¯å¦å®‰å…¨"""
    # åªå…è®¸å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿ã€è¿å­—ç¬¦
    return bool(re.match(r'^[a-zA-Z0-9_-]+$', space_name))

def validate_file_type(filename: str) -> bool:
    """éªŒè¯æ–‡ä»¶ç±»å‹"""
    return any(filename.lower().endswith(ext) for ext in ALLOWED_EXTENSIONS)

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:6408",
        "http://127.0.0.1:6408",
        # æ·»åŠ ä½ çš„æœåŠ¡å™¨åŸŸåï¼Œä¾‹å¦‚ï¼š
        # "https://your-domain.com",
        "http://1.15.95.222:6408"
    ],
    allow_credentials=True,
    allow_methods=["GET", "POST", "DELETE"],
    allow_headers=["*"],
)

# æŒ‚è½½é™æ€æ–‡ä»¶
if os.path.exists("static"):
    app.mount("/static", StaticFiles(directory="static"), name="static")

# çŸ¥è¯†åº“å­˜å‚¨ç›®å½•
KNOWLEDGE_BASE_DIR = "knowledge_bases"

def ensure_knowledge_base_dir():
    """ç¡®ä¿çŸ¥è¯†åº“ç›®å½•å­˜åœ¨"""
    if not os.path.exists(KNOWLEDGE_BASE_DIR):
        os.makedirs(KNOWLEDGE_BASE_DIR)

def get_knowledge_base_path(space_name: str) -> str:
    """è·å–çŸ¥è¯†åº“æ–‡ä»¶è·¯å¾„"""
    return os.path.join(KNOWLEDGE_BASE_DIR, f"{space_name}.json")

def load_knowledge_base(space_name: str) -> List[Dict[str, Any]]:
    """åŠ è½½çŸ¥è¯†åº“æ•°æ®"""
    file_path = get_knowledge_base_path(space_name)
    if os.path.exists(file_path):
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return []

def save_knowledge_base(space_name: str, triples: List[Dict[str, Any]]):
    """ä¿å­˜çŸ¥è¯†åº“æ•°æ®"""
    file_path = get_knowledge_base_path(space_name)
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(triples, f, ensure_ascii=False, indent=2)

def csv_to_triples(csv_content: str, space_name: str) -> List[Dict[str, Any]]:
    """
    æœ€ç®€å•çš„CSVåˆ°ä¸‰å…ƒç»„è½¬æ¢
    æ¯ä¸ªæ ¼å­éƒ½æ˜¯å®ä½“ï¼Œç›¸é‚»æ ¼å­ç”Ÿæˆå…³ç³»
    """
    # è¯»å–CSV
    df = pd.read_csv(io.StringIO(csv_content))
    triples = []
    
    # è·å–æ‰€æœ‰æ ¼å­çš„å€¼
    cells = []
    for i in range(len(df)):
        for j in range(len(df.columns)):
            value = str(df.iloc[i, j]).strip()
            if value and value != 'nan':
                cells.append({
                    'value': value,
                    'row': i,
                    'col': j,
                    'col_name': df.columns[j]
                })
    
    # ç”Ÿæˆè¡Œå†…ç›¸é‚»å…³ç³»
    for i in range(len(cells) - 1):
        if cells[i]['row'] == cells[i+1]['row']:
            triples.append({
                'subject': cells[i]['value'],
                'predicate': 'next_to',
                'object': cells[i+1]['value'],
                'type': 'row_adjacent',
                'space': space_name,
                'created_at': datetime.now().isoformat()
            })
    
    # ç”Ÿæˆè¡¨å¤´å…³ç³»ï¼ˆå¦‚æœç¬¬ä¸€è¡Œæ˜¯è¡¨å¤´ï¼‰
    # if len(df.columns) > 0:
    #     for cell in cells:
    #         if cell['row'] > 0:  # è·³è¿‡è¡¨å¤´è¡Œ
    #             triples.append({
    #                 'subject': cell['value'],
    #                 'predicate': 'has_property',
    #                 'object': cell['col_name'],
    #                 'type': 'header_relation',
    #                 'space': space_name,
    #                 'created_at': datetime.now().isoformat()
    #             })
    
    return triples

@app.post("/parse-csv/{space_name}")
async def parse_csv(space_name: str, file: UploadFile = File(...)):
    """
    ä¸Šä¼ CSVæ–‡ä»¶å¹¶è§£æä¸ºä¸‰å…ƒç»„ï¼Œå­˜å‚¨åˆ°æŒ‡å®šçŸ¥è¯†åº“
    """
    try:
        # éªŒè¯çŸ¥è¯†åº“åç§°
        if not validate_space_name(space_name):
            raise HTTPException(status_code=400, detail="çŸ¥è¯†åº“åç§°åªèƒ½åŒ…å«å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿å’Œè¿å­—ç¬¦")
        
        # éªŒè¯æ–‡ä»¶ç±»å‹
        if not validate_file_type(file.filename):
            raise HTTPException(status_code=400, detail="åªæ”¯æŒCSVæ–‡ä»¶")
        
        # ç¡®ä¿çŸ¥è¯†åº“ç›®å½•å­˜åœ¨
        ensure_knowledge_base_dir()
        
        # è¯»å–CSVæ–‡ä»¶å†…å®¹
        content = await file.read()
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        if len(content) > MAX_FILE_SIZE:
            raise HTTPException(status_code=413, detail=f"æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶ ({MAX_FILE_SIZE // 1024 // 1024}MB)")
        
        # å°è¯•å¤šç§ç¼–ç 
        encodings = ['utf-8', 'gbk', 'gb2312', 'latin-1']
        csv_content = None
        
        for encoding in encodings:
            try:
                csv_content = content.decode(encoding)
                break
            except UnicodeDecodeError:
                continue
        
        if csv_content is None:
            raise HTTPException(status_code=400, detail="æ— æ³•è§£ç æ–‡ä»¶ï¼Œè¯·ç¡®ä¿æ–‡ä»¶ç¼–ç ä¸ºUTF-8ã€GBKæˆ–GB2312")
        
        # è§£æä¸ºä¸‰å…ƒç»„
        new_triples = csv_to_triples(csv_content, space_name)
        
        # åŠ è½½ç°æœ‰çŸ¥è¯†åº“æ•°æ®
        existing_triples = load_knowledge_base(space_name)
        
        # åˆå¹¶æ–°æ•°æ®
        all_triples = existing_triples + new_triples
        
        # ä¿å­˜åˆ°çŸ¥è¯†åº“
        save_knowledge_base(space_name, all_triples)
        
        return JSONResponse({
            "success": True,
            "message": f"æˆåŠŸè§£æå‡º {len(new_triples)} ä¸ªä¸‰å…ƒç»„ï¼Œå·²å­˜å‚¨åˆ°çŸ¥è¯†åº“ '{space_name}'",
            "new_triples": new_triples,
            "total_triples": len(all_triples),
            "space_name": space_name
        })
        
    except HTTPException:
        raise
    except Exception as e:
        return JSONResponse({
            "success": False,
            "message": f"è§£æå¤±è´¥: {str(e)}"
        }, status_code=400)

@app.get("/spaces")
async def list_spaces():
    """åˆ—å‡ºæ‰€æœ‰çŸ¥è¯†åº“"""
    ensure_knowledge_base_dir()
    spaces = []
    for filename in os.listdir(KNOWLEDGE_BASE_DIR):
        if filename.endswith('.json'):
            space_name = filename[:-5]  # å»æ‰.jsonåç¼€
            file_path = os.path.join(KNOWLEDGE_BASE_DIR, filename)
            triples = load_knowledge_base(space_name)
            spaces.append({
                "name": space_name,
                "triple_count": len(triples),
                "created_at": triples[0]['created_at'] if triples and len(triples) > 0 else None
            })
    return {"spaces": spaces}

@app.get("/spaces/{space_name}")
async def get_space_triples(space_name: str, limit: int = 100, offset: int = 0):
    """è·å–æŒ‡å®šçŸ¥è¯†åº“çš„ä¸‰å…ƒç»„"""
    # éªŒè¯çŸ¥è¯†åº“åç§°
    if not validate_space_name(space_name):
        raise HTTPException(status_code=400, detail="çŸ¥è¯†åº“åç§°åªèƒ½åŒ…å«å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿å’Œè¿å­—ç¬¦")
    
    # éªŒè¯åˆ†é¡µå‚æ•°
    if limit < 1 or limit > 1000:
        raise HTTPException(status_code=400, detail="limitå‚æ•°å¿…é¡»åœ¨1-1000ä¹‹é—´")
    if offset < 0:
        raise HTTPException(status_code=400, detail="offsetå‚æ•°ä¸èƒ½ä¸ºè´Ÿæ•°")
    
    triples = load_knowledge_base(space_name)
    total = len(triples)
    paginated_triples = triples[offset:offset + limit]
    
    return {
        "space_name": space_name,
        "total_count": total,
        "limit": limit,
        "offset": offset,
        "triples": paginated_triples
    }

@app.delete("/spaces/{space_name}")
async def delete_space(space_name: str):
    """åˆ é™¤æŒ‡å®šçŸ¥è¯†åº“"""
    # éªŒè¯çŸ¥è¯†åº“åç§°
    if not validate_space_name(space_name):
        raise HTTPException(status_code=400, detail="çŸ¥è¯†åº“åç§°åªèƒ½åŒ…å«å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿å’Œè¿å­—ç¬¦")
    
    file_path = get_knowledge_base_path(space_name)
    if os.path.exists(file_path):
        os.remove(file_path)
        return {"success": True, "message": f"çŸ¥è¯†åº“ '{space_name}' å·²åˆ é™¤"}
    else:
        raise HTTPException(status_code=404, detail=f"çŸ¥è¯†åº“ '{space_name}' ä¸å­˜åœ¨")

@app.get("/")
async def root():
    """é‡å®šå‘åˆ°å‰ç«¯é¡µé¢"""
    return RedirectResponse(url="/static/index.html")

@app.get("/api")
async def api_info():
    """APIä¿¡æ¯"""
    return {
        "message": "CSVä¸‰å…ƒç»„è§£ææœåŠ¡ - æ”¯æŒå¤šçŸ¥è¯†åº“", 
        "version": "2.0",
        "endpoints": {
            "upload": "POST /parse-csv/{space_name}",
            "list_spaces": "GET /spaces",
            "get_triples": "GET /spaces/{space_name}",
            "delete_space": "DELETE /spaces/{space_name}"
        }
    }

if __name__ == "__main__":
    import uvicorn
    import os
    
    # ä»ç¯å¢ƒå˜é‡è·å–ç«¯å£ï¼Œé»˜è®¤ä¸º6408
    port = int(os.getenv('PORT', 6408))
    host = os.getenv('HOST', '0.0.0.0')
    
    print(f"ğŸš€ å¯åŠ¨CSVä¸‰å…ƒç»„è§£ææœåŠ¡...")
    print(f"ğŸ“ æœåŠ¡åœ°å€: http://{host}:{port}")
    print(f"ğŸ“– APIæ–‡æ¡£: http://{host}:{port}/docs")
    print(f"ğŸŒ Webç•Œé¢: http://{host}:{port}")
    
    uvicorn.run(app, host=host, port=port) 